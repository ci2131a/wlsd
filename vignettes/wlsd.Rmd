---
title: "wlsd: Wrangling Longitudinal Survival Data"
author: Charles Ingulli
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  rmarkdown::html_vignette
bibliography: wlsd.bib
nocite: '@*'
vignette: >
  %\VignetteIndexEntry{wlsd}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  collapse = FALSE,
  comment = "#>"
)
load("../data/LBP.rda")
```



# Introduction

Survival analysis is a branch of statistical modeling concerned with the study of time-to-event data (citation needed). However, there are very many techniques and methods for analyzing data in the context of survival whether it be with time or without time. (Author of multivariate survival analysis) uses a continuous time markov model in order to analyze time-to-event data where there exist more than 2 events. Removing time from analysis can lead to many traditional regression models being viewed as survival analysis tools. The odds or relative risk from logistic regression and Poisson regression respectively can be used for predicting survival and therefore could be categorized under this framework. This umbrella discipline of models became the bulk of discussion within my Master's thesis analyzing survival data from the perspective of different survival analysis models. 


As an ancillary project, the `wlsd` package was developed to support the processing of necessary data. The transformation and preparation tasks were performed many times on many data sets that it seemed right to introduce functional programming to improve on the repetition. After that thought it seemed right to just turn it into a package. 

Transitioning between different data formats requires detailed knowledge on how information is parsed and how variables are treated. The `wlsd` package in R provides methods for transforming data between different usable formats in an effort to ease this process. `wlsd` can transition between the counting process format and longitudinal or panel format. 

The package was used within my thesis work and exists to support that analysis while being developed to 


## Data Formats

The relevant data formats that are used in this package are described below and listed here: 
* longitudinal data (panel data) 
* counting process data
    - ?right censored data



### Longitudinal Format

A longitudinal study or panel study analyze subjects over time. It is a repeated observation method by which to investigate a phenomenon citep(grillpanellong). These studies are often carried out over large periods of time with variables of interest being measured at snapshots of the process for each subject citep(cjackson). 
For our purposes, the terms, longitudinal and panel, are interchangeable as they are effectively the same. A more technical definition is given by citet(frees2004) who defines both terms differently but also uses them interchanably. 

We refer to the data generated by a longitudinal study or panel study as longitudinal data or panel data. 
In economics, panel data is used widely to analyze things such as labor markets citep(frees2004). Panel data also sees application to disease progression such as heart deterioration after transplant cite(cjackson). Regardless of its use, the form of the data will remain similar. We produce a small toy example below. We consider 3 individuals 



```{r, echo = FALSE, results = "asis"}
table1 <- data.frame(id = c(1,1,1,1,2,2,2,3,3),
                     time = c(0,31,64,96,0,33,59,0,28),
                     event = c(0,0,0,1,0,0,1,0,1))
knitr::kable(table1, caption = "Table 1: Longitudinal Data")
```




#### Example: Transitioning from Longitudinal Format


In order to transition out of the longitudinal format, several functions exist within 


### Counting Process Format

One common data setup for survival analysis is the counting process format. This data format is organized by a series of time intervals and the variables associated with each interval. Each row in the data set corresponds to a specific time interval where one column defines the start of the interval while another defines the end of the interval. All other columns represent different variable values associated with the interval. This type of data set is most popular when individuals have variables that vary over time. Each time a variable value changes for an individual, it can be represented by a new row with a new time interval. Other variables may include one or more event indicator variable. 
These represent the stat
where the count of the event of interest is assessed at the end of the interval and any explanatory variables are constant over the interval


This stems from the counting process formulation of a Cox PH type model. The formulation that will be described makes the maximum likelihood computation easier to program. Each time interval that may contribute to this likelihood is expressed as a different row so creating the likelihood function is achieved by looking at different rows.

This data is set up with two time variables and an event indicator. The variables describe a time interval between the two time points where the event indicator describes 

<!--
#### Example

Let us consider a survival study of 3 individuals. Individuals are followed from the time of enrollment in the study until the event of interest occurs with monthly follow up visits. The initial visit will be referred to as the baseline where all individuals are assumed to be event free. At the monthly follow ups, individuals are tested to assess whether or not they have experienced the event. Time is represented by intervals between visits with an associated event indicator variable. A visual depiction of the data is shown below in Table 1 where time is measured in days. 

```{r, echo = FALSE, results = "asis"}
table2 <- data.frame(id = c(1,1,1,2,2,3),
                              time1 = c(0,31,64,0,33,0),
                              time2 = c(31,64,96,33,59,28),
                              event = c(0,0,1,0,0,1))
knitr::kable(table2, caption = "Table 2: Counting Process Data")

```

The variable representation of each column is :

* **id** - the individual's identification number.
* **time1** - the left end point of the time interval.
* **time2** - the right end point of the time interval.
* **event** - the event indicator (0 denotes no event and 1 denotes having the event).

Each row of the data corresponds to a particular time interval for each individual. We can see in the first row that individual 1 started the study at time 0 and had a follow up visit 31 days later. At day 31, individual 1 is tested for the event and is determined to have not experienced the event. Time intervals are considered open on the left and closed on the right. That is, for times $t_1$ and $t_2$ where $t_1 < t_2$, the time interval is $(t_1, t_2]$. Looking at the third row, individual 1 starts a new time interval at day 64 and is seen for another follow up at day 96. At time 96, individual 1 is tested and is marked as experiencing the event.


Some data sets may also incorporate one or more explanatory variables. Often in survival studies other variables are measured that possibly relate to the event of interest. These variables may be constant over time or may vary over time. Additionally, they may be qualitative variables or quantitative variables. Consider our previous example of 3 individuals. Let's say that in addition to measuring for the event of interest, individuals were also measured for age at baseline and the amount of medication they receive at that appointment. The former can be considered a constant variable while the latter can be considered a time varying variable. An individual's age at baseline will not change but the amount of medication received by a patient in a survival study may change as the illness progresses. Both constant and time varying variables have a big effect on how the data set is organized as each row is used for a single time interval. 


The coding for new variables is:

* **age** - the numerical age of the individual in years at their baseline visit.
* **meds** - the level of medication received by an individual between visits (0 is for low, 1 is for medium, and 2 is for high).

In this example, age is a constant quantitative variable where as meds is a time varying qualitative variable. We create 3 levels for meds where individuals can be classified as receiving a low, medium, or high amount of medication.
Table 2 shows how these additional explanatory variables would be incorporated in counting process format.

```{r, echo = FALSE, results = "asis"}
table3 <- data.frame(id = c(1,1,1,2,2,3),
                     time1 = c(0,31,64,0,33,0),
                     time2 = c(31,64,96,33,59,28),
                     event = c(0,0,1,0,0,1),
                     age = c(46,46,46,39,39,57),
                     meds = c(0,1,2,0,1,2)
                     )
knitr::kable(table3, caption = "Table 3: Counting Process Data with Explanatory Variables")

```



The constant variables have the same interpretation at every time point. Individual 1 was measured to be 46 years at baseline and each subsequent visit individual 1 was still 46 years at baseline.


Time varying variables require a bit more interpretation. Even though the variables technically vary over time, they are considered to be constant between intervals (Cite). The intervals are still set up to be open on the left and closed on the right. Looking at individual 1 in Table 2, we can interpret the variables of the first row as the baseline visit. This means that at the baseline time of 0 this individual has a meds level of 0 corresponding to a low amount of medication received. At the first follow-up visit, time 31, the medication level is measured again and assigned a new value, medium. However, because of the way the intervals are set up this value does not yet take effect. The new value clicks in immediately after the follow-up visit. Individual 1's complete meds values are 0 for $(0,31]$, 1 for $(31,64]$, and 2 for $(64,96]$. Even though the value of 1 was measured at time 31, it applies to the following interval.




### Right Censored Format


With the absence of time-dependent variables, the multiple rows of Table 1 do not provide additional information toward the time to event. A simplified form of the counting process data is often used instead. This form is called right censored data where each row corresponds to a single individual with their respective survival time. Censoring refers to an individual that does not experience the event during the period of study. In Table 1 and Table 2, individual 2 is considered censored, specifically right censored since they have not yet experienced the event by the end of their study time but will still experience the event after their observation times. The topic of censoring is outside the scope of this vignette but see (Cite) for more information. Table 3 shows an example of our survival study in right censored format. 

```{r, echo=FALSE, results = "asis"}
table4 <- data.frame(sid = c(1,2,3),
                     time1 = c(0,0,0),
                     time2 = c(96,33,28),
                     status = c(1,0,1))
knitr::kable(table4, caption = "Table 4: Right Censored Data",table.attr = "style='width:200%;'")

```

This form conveys the similar information as the previous in regard to survival time. Within the time interval $(0, 96]$, individual 1 experiences the event. With the absence of time-dependent variables, we can consolidate all follow-up intervals into one larger interval to more consicesly convey the time to event.


Additional simplifications are also possible. Since all individuals start at the same time point the start variable can be ommitted. That is, in this example, since each individual enrolls in the study at time 0, we do not need the start variable column. It can then be clearly stated all individuals start at time 0  and we need only include the possible event time.
-->

### Count Format

Count data format for count regression.

## Application

The data formats described thus far are used for different statistical models. The counting process format is widely used in the `survival` package for implementing different proportional hazards models such as the Cox-proportional hazards model. The `flexsurv` package also uses this format and extends the `survival` package to add more flexible parametric proportional hazards models. The `msm` package uses the logitudinal data format to fit multi-state models. 





# Utilization

The `wlsd` package contains several functions for working with longitudinal survival data. This section will provide a number of working examples in order to explain how to install and use the package efficiently.


## Installation


The development version of the package resides on GitHub at the following link: <https://github.com/ci2131a/wlsd>. It can be installed by running the code below. This installation requires the `devtools` package. If you have not already installed `devtools`, it can be installed by the traditional means from the comprehensive R archive network (CRAN) using `install.packages("devtools")`. Once `devtools` is installed you can download the `wlsd` package through the following code:


```{r install, echo = TRUE, eval=FALSE}
devtools::install_github("ci2131a/wlsd")
```

Once the package is installed, we can add the package into our loaded memory through 

```{r, echo=TRUE, results="hide", warning=FALSE}
library(wlsd)
```

for ease of use. Currently, the package is not available on CRAN and only exists as a developing package. Future iterations may find their way to such a platform.


## Included Data Set

The package makes available a data set studying low back pain (LBP) in a cohort of manufacturing workers. Information on the data set is discussed in citet(). It looks at individuals working in various industrial plants across the midwest United States. Individuals enrolled are initially assessed at what is known as a baseline visit. This visit determines whether individuals qualify for the study and measure a number of explanatory variables. The qualified individuals are scheduled for approximate monthly follow-up visits where individuals are asked a series of questions relating to the level of severity of their back pain.

The full data set can be accessed by the command `LBP` in R. The data for the first individual is shown below. 


```{r, echo=TRUE}
head(LBP, n = 17)
```

This individual contributes 17 rows of data and there are 23 columns of variables. The subject identification number is given by `sid`. The `Baseline.date` shows the date of the first assessment while `Date` marks the date of the follow-up visit. The `time_to_row` denotes the time difference in days between the baseline visit and the time of follow-up. Variables that begin with `case.` are the status indicators of interest. Each indicator has 2 levels where 0 represents not having the event and 1 represents having the event. More information on the data set can by found using either of the following commands.

```{r, echo = T, eval = F}
help(LBP)
# or 
?LBP
```



## Longitudinal Data

The LBP data is formated in the long form of longitudinal data. Each time point has a distinct row and all variables associated with that time are contained in the other columns. One exception to this claim is the baseline date variable. This information is stored in a separate column which conflicts with the previous statement. In order to deal with this, we can use the `basedate` function to consolidate information.
The function will create a new entry for each individual with their baseline date information in the follow-up column. The function works as follows:

```{r, echo=TRUE}
long.data <- basedate(LBP,"sid","Baseline.date","Date",tvars = c("time_to_row","case.lbp","case.med","case.sc","case.lt"))
```
We save the resulting data frame as `longdata` and display the first individual again.

```{r, echo = TRUE}
head(long.data, n = 17)
```

Note the arguement `tvars`. This argument is used for a single or multiple variables that are time-dependent. That is, the value of these variables change with time. To this argument, we supplied the `time_to_row` variable  and the status indicator variables which are all dependent on the timed follow-up visits. The `basedate` function will add `NA`s to the values of these variables in the new row since they were unknown based on the data set. Since the `time_to_row` variable is defined to be the difference to the baseline date in days, we can replace these `NA`s with 0 as the number of days between the same date is 0. 

```{r, echo = TRUE}
is.na(long.data$time_to_row) <- 0
```

Additionally, since entrants to the study are required to be LBP free at the time of baseline visit, we can update the values in the status indicator variables to also be 0 citep().

```{r, echo=T}
long.data[is.na(long.data)] <- 0
```

There are no other time-dependent variables in the data set so there are no other columns to change.





## Count Data


If we are looking to explore the relationships between the number of events given by the different LBP status indicators for each individual and the other variables, we may look to count regression. To transition from a data set that is long form longitudinal data to a count format, we can use the `long2count` function. This can be used to tally the total number of events observed for each individual. Using the `longdata` from the previous example, we can transition as follows:

```{r, echo=T}
count.data <- long2count(long.data, "sid", event = c("case.lbp","case.med","case.sc","case.lt"))
head(count.data,n = 5)
```
The resulting data frame for the first 5 individuals is shown above. We can see the function summed accross all LBP variables and added a new variable called `count.weight` which is the total number of rows for each individual in the supplied data frame. This variable can be used as the offset variable in count regression to represent the number of visits experienced. Since all variables of interest in the data set are constant, we do not supply any additional arguments to the function and it will return the first row value for each individual. Note the `time_to_row` variable has all 0 entries since we changed the first entry for each individual to be 0. 


If we would like to include a time-dependent variable, we must find another statistic to display the information in one row. For example, we can look at the mean value for each invidual. In the `long2count` function the argument `tvars` allows you to specify any number of time-dependent variables, while `tfun` will take a summary function to be applied to the variables in `tvars`. Let us use the `time_to_row` variable as an example. This variable has no trivial interpretation but can be used to demonstrate the arguments.

```{r, echo=T}
time.count.data <- long2count(long.data, "sid", event = c("case.lbp","case.med","case.sc","case.lt"), tvars = "time_to_row", tfun = mean)
head(time.count.data, n = 5)
```

We can see that the output is identical with the exception of the `time_to_row` variable which has had the mean function applied to each individual. The `tfun` argument will take any summary function such as mean, median, max, etc. The default option will apply the mean to the variables. 


# References

<!-- 
Therune survival vignette
Ther book
Collett
jackson paper
jackson vignette
-->



